{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36978672",
   "metadata": {},
   "source": [
    "## Data Preprocessing and PyTorch Setup Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0e3b67a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b06aad",
   "metadata": {},
   "source": [
    "## Load Cleaned Classification Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5a87e58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('classification_dataset_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05068159",
   "metadata": {},
   "source": [
    "## Check Missing Values in Each Column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e2d40366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feature1          0\n",
       "Feature2          0\n",
       "NumFeature3    1000\n",
       "CatFeature1     500\n",
       "CatFeature2       0\n",
       "Class             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3abae75",
   "metadata": {},
   "source": [
    "## Define Preprocessing Pipelines for Categorical and Numerical Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "541e8541",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = df.select_dtypes('object').columns.tolist()\n",
    "numerical_cols = df.select_dtypes(include='number').columns.drop('Class').tolist()\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('nan', SimpleImputer(strategy='most_frequent')),\n",
    "    ('tonum', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('nan', SimpleImputer(strategy='median')),\n",
    "])\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('categorical_cols', categorical_pipeline, categorical_cols),\n",
    "    ('numerical_cols', numerical_pipeline, numerical_cols)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8444bc",
   "metadata": {},
   "source": [
    "## Split Features and Target Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ae8c7807",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[numerical_cols + categorical_cols]\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efb7d42",
   "metadata": {},
   "source": [
    "## Fit Preprocessor and Transform Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e8c44749",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor.fit(X)\n",
    "X_transformed = preprocessor.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37922cf",
   "metadata": {},
   "source": [
    "## Split Data into Training and Test Sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c64cf92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, train_size=0.8, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b78eabb",
   "metadata": {},
   "source": [
    "## Define a Simple Binary Classifier Neural Network in PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "fa19e4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class binaryclassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Linear(X_train.shape[1], 5)\n",
    "        self.layer_2 = nn.Linear(5, 1)\n",
    "    def forward(self, x):\n",
    "        x = self.layer_1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = nn.Sigmoid()(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338b3de5",
   "metadata": {},
   "source": [
    "## Convert Training Data to PyTorch Tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "97ebfec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values.reshape(-1, 1), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a8a2c1",
   "metadata": {},
   "source": [
    "## Initialize Model, Loss Function, Optimizer, and Train for  1000 Epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5540a02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = binaryclassifier()\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    y_pred = model(X_train_tensor)\n",
    "    loss = loss_fn(y_pred, y_train_tensor)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb35d1de",
   "metadata": {},
   "source": [
    "## Convert Test Data to PyTorch Tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2dbfa143",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values.reshape(-1, 1), dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34315a02",
   "metadata": {},
   "source": [
    "## Evaluate Model on Test Data and Generate Binary Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "92f7f84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_probs = model(X_test_tensor)\n",
    "    y_pred_labels = (y_pred_probs >= 0.5).float()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a2b135",
   "metadata": {},
   "source": [
    "## Calculate and Print Test Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3544bf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9980\n"
     ]
    }
   ],
   "source": [
    "accuracy = (y_pred_labels == y_test_tensor).float().mean()\n",
    "print(f\"Test Accuracy: {accuracy.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781b3edf",
   "metadata": {},
   "source": [
    "## Display Class Distribution in the Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "097a3c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "1    0.5022\n",
      "0    0.4978\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['Class'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6721d2e6",
   "metadata": {},
   "source": [
    "## Compute and Display Confusion Matrix for Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4586bfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[999   0]\n",
      " [  4 997]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test_tensor, y_pred_labels)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75367a50",
   "metadata": {},
   "source": [
    "## Calculate and Print Precision, Recall, and F1 Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "923d2b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0000\n",
      "Recall: 0.9960\n",
      "F1 Score: 0.9980\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(y_test_tensor, y_pred_labels)\n",
    "recall = recall_score(y_test_tensor, y_pred_labels)\n",
    "f1 = f1_score(y_test_tensor, y_pred_labels)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
